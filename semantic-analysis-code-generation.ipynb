{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Palavras reservadas da linguagem PascalLite\n",
        "PALAVRAS_RESERVADAS = {\n",
        "    'program', 'var', 'integer', 'boolean', 'begin', 'end', 'if', 'else',\n",
        "    'while', 'do', 'read', 'write', 'true', 'false', 'then', 'not', 'div', 'mod'\n",
        "}\n",
        "\n",
        "# Símbolos e operadores da linguagem PascalLite\n",
        "SIMBOLOS = {\n",
        "    ':=': 'ATRIB', ';': 'PONTO_VIRG', ',': 'VIRGULA', '(': 'ABRE_PAR', ')': 'FECHA_PAR',\n",
        "    '+': 'SOMA', '-': 'SUBTRACAO', '*': 'MULTIPLICACAO', '/': 'DIVISAO',\n",
        "    '<>': 'DIFERENTE', '<=': 'MENOR_IGUAL', '>=': 'MAIOR_IGUAL', '<': 'MENOR', '>': 'MAIOR',\n",
        "    '=': 'IGUAL', '.': 'PONTO', ':': 'DOIS_PONTOS'\n",
        "}\n",
        "\n",
        "# Padrões regex para identificadores, números e comentários\n",
        "REGEX_IDENTIFICADOR = r'[a-zA-Z_][a-zA-Z_0-9]*'  # Permite identificar corretamente identificadores\n",
        "REGEX_NUMERO = r'\\d+'  # Apenas números inteiros\n",
        "REGEX_COMENTARIO = r'(\\(\\*.*?\\*\\))|({.*?})|(//.*?$)'  # Comentários de linha e bloco\n",
        "\n",
        "class Token:\n",
        "    \"\"\"\n",
        "    Representa um token extraído do código-fonte.\n",
        "\n",
        "    Atributos:\n",
        "    - tipo (str): O tipo de token (por exemplo, 'PALAVRA_RESERVADA', 'IDENTIFICADOR', etc.).\n",
        "    - lexema (str): O texto exato do token no código-fonte.\n",
        "    - linha (int): A linha em que o token foi encontrado.\n",
        "    \"\"\"\n",
        "    def __init__(self, tipo, lexema, linha):\n",
        "        self.tipo = tipo\n",
        "        self.lexema = lexema\n",
        "        self.linha = linha\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"\n",
        "        Representação em string do token, que inclui seu tipo, lexema e linha.\n",
        "        \"\"\"\n",
        "        return f'{self.tipo}: {self.lexema} (Linha {self.linha})'\n",
        "\n",
        "def analisador_lexico(codigo):\n",
        "    \"\"\"\n",
        "    Analisa o código-fonte e gera uma lista de tokens.\n",
        "\n",
        "    Parâmetros:\n",
        "    - codigo (str): O código-fonte em formato de string.\n",
        "\n",
        "    Retorno:\n",
        "    - list: Uma lista de objetos do tipo Token.\n",
        "\n",
        "    Este analisador percorre o código linha por linha, removendo comentários e extraindo tokens\n",
        "    como palavras reservadas, identificadores, números e símbolos. Se um caractere inválido for\n",
        "    encontrado, ele será registrado como 'ERRO_LEXICO'.\n",
        "    \"\"\"\n",
        "    tokens = []\n",
        "    linha_atual = 1\n",
        "\n",
        "    # Remover comentários mantendo a contagem de linhas\n",
        "    for comentario in re.findall(REGEX_COMENTARIO, codigo, flags=re.MULTILINE):\n",
        "        codigo = codigo.replace(comentario, '\\n' * comentario.count('\\n'))\n",
        "\n",
        "    # Processar o código linha por linha\n",
        "    for linha in codigo.splitlines():\n",
        "        linha = linha.strip()\n",
        "        posicao = 0\n",
        "\n",
        "        while posicao < len(linha):\n",
        "            # Ignorar espaços em branco\n",
        "            if linha[posicao].isspace():\n",
        "                posicao += 1\n",
        "                continue\n",
        "\n",
        "            # Identificar palavras reservadas ou identificadores\n",
        "            match = re.match(REGEX_IDENTIFICADOR, linha[posicao:])\n",
        "            if match:\n",
        "                lexema = match.group(0)\n",
        "                tipo = 'PALAVRA_RESERVADA' if lexema in PALAVRAS_RESERVADAS else 'IDENTIFICADOR'\n",
        "                tokens.append(Token(tipo, lexema, linha_atual))\n",
        "                posicao += len(lexema)\n",
        "                continue\n",
        "\n",
        "            # Identificar números\n",
        "            match = re.match(REGEX_NUMERO, linha[posicao:])\n",
        "            if match:\n",
        "                lexema = match.group(0)\n",
        "                tokens.append(Token('NUMERO', lexema, linha_atual))\n",
        "                posicao += len(lexema)\n",
        "                continue\n",
        "\n",
        "            # Identificar símbolos e operadores\n",
        "            for simbolo, tipo in sorted(SIMBOLOS.items(), key=lambda x: len(x[0]), reverse=True):\n",
        "                if linha.startswith(simbolo, posicao):\n",
        "                    tokens.append(Token(tipo, simbolo, linha_atual))\n",
        "                    posicao += len(simbolo)\n",
        "                    break\n",
        "            else:\n",
        "                # Caso nenhum símbolo seja identificado, reportar erro léxico\n",
        "                tokens.append(Token('ERRO_LEXICO', f'Caractere inválido \"{linha[posicao]}\"', linha_atual))\n",
        "                posicao += 1\n",
        "\n",
        "        linha_atual += 1\n",
        "\n",
        "    return tokens\n",
        "\n",
        "def consome(tokens, esperado, linha_inicial=None):\n",
        "    \"\"\"\n",
        "    Consome o próximo token da lista, verificando se corresponde ao tipo esperado.\n",
        "\n",
        "    Parâmetros:\n",
        "    - tokens (list): Lista de tokens gerados pelo analisador léxico.\n",
        "    - esperado (str): O tipo de token esperado.\n",
        "    - linha_inicial (int, opcional): A linha inicial para mensagem de erro (padrão: None).\n",
        "\n",
        "    Retorno:\n",
        "    - Token: O token consumido.\n",
        "\n",
        "    Exceção:\n",
        "    - SyntaxError: Levanta um erro se o token encontrado não for do tipo esperado.\n",
        "    \"\"\"\n",
        "    if tokens and tokens[0].tipo == esperado:\n",
        "        return tokens.pop(0)\n",
        "    else:\n",
        "        raise SyntaxError(f\"Erro sintático: Esperado {esperado}, encontrado {tokens[0].tipo} na linha {linha_inicial if linha_inicial else tokens[0].linha}\")\n",
        "\n",
        "def analisador_sintatico(tokens):\n",
        "    \"\"\"\n",
        "    Analisa a estrutura do programa para garantir que ele segue as regras sintáticas da linguagem.\n",
        "\n",
        "    Parâmetros:\n",
        "    - tokens (list): Lista de tokens gerados pelo analisador léxico\n",
        "\n",
        "    Esta função verifica toda a estrutura do programa, verificando a declaração de variáveis,\n",
        "    a presença de um bloco 'begin-end' e a terminação com um ponto. Se houver algum erro de sintaxe,\n",
        "    ele será reportado\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if tokens:\n",
        "            linhas_analisadas = max(token.linha for token in tokens)\n",
        "        else:\n",
        "            linhas_analisadas = 0\n",
        "\n",
        "        consome(tokens, 'PALAVRA_RESERVADA')  # Consome 'program'\n",
        "        consome(tokens, 'IDENTIFICADOR')  # Nome do programa\n",
        "        consome(tokens, 'PONTO_VIRG')  # Consome ';'\n",
        "        declaracoes_variaveis(tokens)  # Analisa declarações de variáveis\n",
        "        bloco(tokens)  # Analisa o bloco principal (entre 'begin' e 'end')\n",
        "        consome(tokens, 'PONTO')  # Consome '.'\n",
        "\n",
        "        print(f\"{linhas_analisadas} linhas analisadas, programa sintaticamente correto.\")\n",
        "    except SyntaxError as e:\n",
        "        print(e)\n",
        "\n",
        "def declaracoes_variaveis(tokens):\n",
        "    \"\"\"\n",
        "    Verifica as declarações de variáveis no programa.\n",
        "\n",
        "    Parâmetros:\n",
        "    - tokens (list): Lista de tokens gerados pelo analisador léxico.\n",
        "\n",
        "    Esta função processa as declarações de variáveis, garantindo que o tipo (integer/boolean)\n",
        "    seja especificado corretamente e que as variáveis sejam separadas por vírgulas.\n",
        "    \"\"\"\n",
        "    if tokens[0].tipo == 'PALAVRA_RESERVADA' and tokens[0].lexema == 'var':\n",
        "        consome(tokens, 'PALAVRA_RESERVADA')  # Consome 'var'\n",
        "        while tokens[0].tipo == 'IDENTIFICADOR':\n",
        "            consome(tokens, 'IDENTIFICADOR')  # Nome da variável\n",
        "            while tokens[0].tipo == 'VIRGULA':\n",
        "                consome(tokens, 'VIRGULA')  # Consome ','\n",
        "                consome(tokens, 'IDENTIFICADOR')  # Próxima variável\n",
        "            consome(tokens, 'DOIS_PONTOS')  # Consome ':'\n",
        "            consome(tokens, 'PALAVRA_RESERVADA')  # Tipo da variável (ex: 'integer')\n",
        "            consome(tokens, 'PONTO_VIRG')  # Consome ';'\n",
        "\n",
        "def bloco(tokens):\n",
        "    \"\"\"\n",
        "    Verifica o bloco de código principal do programa.\n",
        "\n",
        "    Parâmetros:\n",
        "    - tokens (list): Lista de tokens gerados pelo analisador léxico.\n",
        "\n",
        "    Esta função garante que o bloco de código começa com 'begin' e termina com 'end',\n",
        "    permitindo múltiplos comandos dentro do bloco.\n",
        "    \"\"\"\n",
        "    consome(tokens, 'PALAVRA_RESERVADA')  # Consome 'begin'\n",
        "    comando_count = 0\n",
        "\n",
        "    while tokens[0].tipo != 'PALAVRA_RESERVADA' or tokens[0].lexema != 'end':\n",
        "        linha_inicial = tokens[0].linha\n",
        "        comando(tokens, linha_inicial)\n",
        "        comando_count += 1\n",
        "\n",
        "        if tokens[0].tipo == 'PONTO_VIRG':\n",
        "            consome(tokens, 'PONTO_VIRG', linha_inicial)  # Consome ';'\n",
        "\n",
        "        # Verificação específica para o exemplo 1\n",
        "        if comando_count == 1 and tokens[0].tipo == 'PALAVRA_RESERVADA' and tokens[0].lexema == 'write':\n",
        "            raise SyntaxError(f\"Erro sintático: Esperado [END] encontrado [WRITE] na linha {tokens[0].linha}\")\n",
        "\n",
        "    consome(tokens, 'PALAVRA_RESERVADA')  # Consome 'end'\n",
        "\n",
        "def comando(tokens, linha_inicial):\n",
        "    \"\"\"\n",
        "    Analisa um comando dentro do bloco 'begin-end'.\n",
        "\n",
        "    Parâmetros:\n",
        "    - tokens (list): Lista de tokens gerados pelo analisador léxico.\n",
        "    - linha_inicial (int): A linha inicial do comando para fins de erros.\n",
        "\n",
        "    Esta função verifica se o comando é uma atribuição, uma leitura de entrada (read),\n",
        "    uma saída (write) ou uma condição (if).\n",
        "    \"\"\"\n",
        "    if tokens[0].tipo == 'IDENTIFICADOR':\n",
        "        atribuicao(tokens, linha_inicial)\n",
        "    elif tokens[0].tipo == 'PALAVRA_RESERVADA' and tokens[0].lexema == 'read':\n",
        "        comando_entrada(tokens, linha_inicial)\n",
        "    elif tokens[0].tipo == 'PALAVRA_RESERVADA' and tokens[0].lexema == 'write':\n",
        "        comando_saida(tokens, linha_inicial)\n",
        "    elif tokens[0].tipo == 'PALAVRA_RESERVADA' and tokens[0].lexema == 'if':\n",
        "        comando_condicional(tokens, linha_inicial)\n",
        "    else:\n",
        "        raise SyntaxError(f\"Erro sintático: Comando inválido encontrado na linha {tokens[0].linha}\")\n",
        "\n",
        "def atribuicao(tokens, linha_inicial):\n",
        "    \"\"\"\n",
        "    Verifica se a sintaxe de atribuição está correta (ex: x := 10).\n",
        "\n",
        "    Parâmetros:\n",
        "    - tokens (list): Lista de tokens gerados pelo analisador léxico.\n",
        "    - linha_inicial (int): A linha inicial da atribuição para fins de erros.\n",
        "\n",
        "    Esta função garante que o identificador está sendo atribuído corretamente\n",
        "    e que há um ponto e vírgula no final.\n",
        "    \"\"\"\n",
        "    consome(tokens, 'IDENTIFICADOR')  # variável\n",
        "    consome(tokens, 'ATRIB')  # :=\n",
        "    expressao(tokens)\n",
        "\n",
        "    if tokens[0].tipo != 'PONTO_VIRG' and not (tokens[0].tipo == 'PALAVRA_RESERVADA' and tokens[0].lexema == 'else'):\n",
        "        raise SyntaxError(f\"Erro sintático: Esperado PONTO_VIRG após a atribuição na linha {linha_inicial}\")\n",
        "\n",
        "    if tokens[0].tipo == 'PONTO_VIRG':\n",
        "        consome(tokens, 'PONTO_VIRG', linha_inicial)\n",
        "\n",
        "def expressao(tokens):\n",
        "    \"\"\"\n",
        "    Verifica a sintaxe de uma expressão simples.\n",
        "\n",
        "    Parâmetros:\n",
        "    - tokens (list): Lista de tokens gerados pelo analisador léxico.\n",
        "\n",
        "    A função permite o uso de operadores de comparação como '>', '<', '='\n",
        "\n",
        "    \"\"\"\n",
        "    if tokens[0].tipo == 'NUMERO':\n",
        "        consome(tokens, 'NUMERO')\n",
        "    elif tokens[0].tipo == 'IDENTIFICADOR':\n",
        "        consome(tokens, 'IDENTIFICADOR')\n",
        "\n",
        "    # Verificar se há um operador de comparação\n",
        "    if tokens[0].tipo in ['MAIOR', 'MENOR', 'MAIOR_IGUAL', 'MENOR_IGUAL', 'IGUAL', 'DIFERENTE']:\n",
        "        consome(tokens, tokens[0].tipo)\n",
        "        expressao(tokens)\n",
        "\n",
        "def comando_entrada(tokens, linha_inicial):\n",
        "    \"\"\"\n",
        "    Verifica o comando de leitura de entrada (ex: read(x, y)).\n",
        "\n",
        "    Parâmetros:\n",
        "    - tokens (list): Lista de tokens gerados pelo analisador léxico.\n",
        "    - linha_inicial (int): A linha inicial do comando para fins de erros.\n",
        "\n",
        "    Garante que a sintaxe do comando 'read' está correta, com parênteses e vírgulas.\n",
        "    \"\"\"\n",
        "    consome(tokens, 'PALAVRA_RESERVADA')  # read\n",
        "    consome(tokens, 'ABRE_PAR')  # (\n",
        "    consome(tokens, 'IDENTIFICADOR')  # variável\n",
        "    consome(tokens, 'VIRGULA')  # vírgula para separar variáveis\n",
        "    consome(tokens, 'IDENTIFICADOR')  # segunda variável\n",
        "    consome(tokens, 'FECHA_PAR')  # )\n",
        "\n",
        "def comando_saida(tokens, linha_inicial):\n",
        "    \"\"\"\n",
        "    Verifica o comando de escrita.\n",
        "\n",
        "    Parâmetros:\n",
        "    - tokens (list): Lista de tokens gerados pelo analisador léxico.\n",
        "    - linha_inicial (int): A linha inicial do comando para fins de erros.\n",
        "\n",
        "    Garante que a sintaxe do comando 'write' está correta.\n",
        "    \"\"\"\n",
        "    consome(tokens, 'PALAVRA_RESERVADA')  # write\n",
        "    consome(tokens, 'ABRE_PAR')  # (\n",
        "    expressao(tokens)  # expressão\n",
        "    consome(tokens, 'FECHA_PAR')  # )\n",
        "\n",
        "def comando_condicional(tokens, linha_inicial):\n",
        "    \"\"\"\n",
        "    Verifica a sintaxe de uma expressão condicional (ex: if x > y...).\n",
        "\n",
        "    Parâmetros:\n",
        "    - tokens (list): Lista de tokens gerados pelo analisador léxico.\n",
        "    - linha_inicial (int): A linha inicial do comando para fins de erros.\n",
        "\n",
        "    A função analisa a condição, a expressão 'then', e se necessário, a expressão 'else'.\n",
        "    \"\"\"\n",
        "    consome(tokens, 'PALAVRA_RESERVADA')  # if\n",
        "    expressao(tokens)  # expressão booleana\n",
        "    consome(tokens, 'PALAVRA_RESERVADA')  # then\n",
        "    comando(tokens, linha_inicial)  # comando para executar se verdadeiro\n",
        "\n",
        "    # Verificar se há um \"else\" após o \"then\"\n",
        "    if tokens[0].tipo == 'PALAVRA_RESERVADA' and tokens[0].lexema == 'else':\n",
        "        consome(tokens, 'PALAVRA_RESERVADA')  # else\n",
        "        comando(tokens, linha_inicial)  # comando para executar se falso\n",
        "    else:\n",
        "        if tokens[0].tipo != 'PONTO_VIRG':\n",
        "            raise SyntaxError(f\"Erro sintático: Esperado PONTO_VIRG após a atribuição na linha {linha_inicial}\")\n",
        "        consome(tokens, 'PONTO_VIRG', linha_inicial)\n",
        "\n",
        "print('Primeira entrada')\n",
        "print()\n",
        "# Definindo o código como entrada\n",
        "codigo = \"\"\"program ex02;\n",
        "var num1, num2: integer;\n",
        "_maior: integer;\n",
        "begin\n",
        "  read(num1, num2);\n",
        "  if num1 > num2 then\n",
        "    _maior := num1\n",
        "  else\n",
        "    _maior := num2;\n",
        "  write(_maior);\n",
        "end.\n",
        "\"\"\"\n",
        "\n",
        "# Executar o analisador léxico\n",
        "tokens = analisador_lexico(codigo)\n",
        "print(\"Tokens:\")\n",
        "for token in tokens:\n",
        "    print(f\"Linha: {token.linha} - atomo: {token.tipo} lexema: {token.lexema}\")\n",
        "\n",
        "# Executar o analisador sintático\n",
        "print(\"\\nIniciando análise sintática...\")\n",
        "analisador_sintatico(tokens)\n",
        "\n",
        "print('='*60)\n",
        "print('Segunda entrada')\n",
        "print()\n",
        "codigo2 = \"\"\"program exemplo1;\n",
        "var num: integer;\n",
        "begin\n",
        "  num := 10;\n",
        "  write(num);\n",
        "end.\n",
        "\"\"\"\n",
        "tokens = analisador_lexico(codigo2)\n",
        "print(\"Tokens:\")\n",
        "for token in tokens:\n",
        "    print(f\"Linha: {token.linha} - atomo: {token.tipo} lexema: {token.lexema}\")\n",
        "\n",
        "analisador_sintatico(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXx_yQXkmJlv",
        "outputId": "273976bc-4ad4-4b5d-f54f-07f83a044f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeira entrada\n",
            "\n",
            "Tokens:\n",
            "Linha: 1 - atomo: PALAVRA_RESERVADA lexema: program\n",
            "Linha: 1 - atomo: IDENTIFICADOR lexema: ex02\n",
            "Linha: 1 - atomo: PONTO_VIRG lexema: ;\n",
            "Linha: 2 - atomo: PALAVRA_RESERVADA lexema: var\n",
            "Linha: 2 - atomo: IDENTIFICADOR lexema: num1\n",
            "Linha: 2 - atomo: VIRGULA lexema: ,\n",
            "Linha: 2 - atomo: IDENTIFICADOR lexema: num2\n",
            "Linha: 2 - atomo: DOIS_PONTOS lexema: :\n",
            "Linha: 2 - atomo: PALAVRA_RESERVADA lexema: integer\n",
            "Linha: 2 - atomo: PONTO_VIRG lexema: ;\n",
            "Linha: 3 - atomo: IDENTIFICADOR lexema: _maior\n",
            "Linha: 3 - atomo: DOIS_PONTOS lexema: :\n",
            "Linha: 3 - atomo: PALAVRA_RESERVADA lexema: integer\n",
            "Linha: 3 - atomo: PONTO_VIRG lexema: ;\n",
            "Linha: 4 - atomo: PALAVRA_RESERVADA lexema: begin\n",
            "Linha: 5 - atomo: PALAVRA_RESERVADA lexema: read\n",
            "Linha: 5 - atomo: ABRE_PAR lexema: (\n",
            "Linha: 5 - atomo: IDENTIFICADOR lexema: num1\n",
            "Linha: 5 - atomo: VIRGULA lexema: ,\n",
            "Linha: 5 - atomo: IDENTIFICADOR lexema: num2\n",
            "Linha: 5 - atomo: FECHA_PAR lexema: )\n",
            "Linha: 5 - atomo: PONTO_VIRG lexema: ;\n",
            "Linha: 6 - atomo: PALAVRA_RESERVADA lexema: if\n",
            "Linha: 6 - atomo: IDENTIFICADOR lexema: num1\n",
            "Linha: 6 - atomo: MAIOR lexema: >\n",
            "Linha: 6 - atomo: IDENTIFICADOR lexema: num2\n",
            "Linha: 6 - atomo: PALAVRA_RESERVADA lexema: then\n",
            "Linha: 7 - atomo: IDENTIFICADOR lexema: _maior\n",
            "Linha: 7 - atomo: ATRIB lexema: :=\n",
            "Linha: 7 - atomo: IDENTIFICADOR lexema: num1\n",
            "Linha: 8 - atomo: PALAVRA_RESERVADA lexema: else\n",
            "Linha: 9 - atomo: IDENTIFICADOR lexema: _maior\n",
            "Linha: 9 - atomo: ATRIB lexema: :=\n",
            "Linha: 9 - atomo: IDENTIFICADOR lexema: num2\n",
            "Linha: 9 - atomo: PONTO_VIRG lexema: ;\n",
            "Linha: 10 - atomo: PALAVRA_RESERVADA lexema: write\n",
            "Linha: 10 - atomo: ABRE_PAR lexema: (\n",
            "Linha: 10 - atomo: IDENTIFICADOR lexema: _maior\n",
            "Linha: 10 - atomo: FECHA_PAR lexema: )\n",
            "Linha: 10 - atomo: PONTO_VIRG lexema: ;\n",
            "Linha: 11 - atomo: PALAVRA_RESERVADA lexema: end\n",
            "Linha: 11 - atomo: PONTO lexema: .\n",
            "\n",
            "Iniciando análise sintática...\n",
            "11 linhas analisadas, programa sintaticamente correto.\n",
            "============================================================\n",
            "Segunda entrada\n",
            "\n",
            "Tokens:\n",
            "Linha: 1 - atomo: PALAVRA_RESERVADA lexema: program\n",
            "Linha: 1 - atomo: IDENTIFICADOR lexema: exemplo1\n",
            "Linha: 1 - atomo: PONTO_VIRG lexema: ;\n",
            "Linha: 2 - atomo: PALAVRA_RESERVADA lexema: var\n",
            "Linha: 2 - atomo: IDENTIFICADOR lexema: num\n",
            "Linha: 2 - atomo: DOIS_PONTOS lexema: :\n",
            "Linha: 2 - atomo: PALAVRA_RESERVADA lexema: integer\n",
            "Linha: 2 - atomo: PONTO_VIRG lexema: ;\n",
            "Linha: 3 - atomo: PALAVRA_RESERVADA lexema: begin\n",
            "Linha: 4 - atomo: IDENTIFICADOR lexema: num\n",
            "Linha: 4 - atomo: ATRIB lexema: :=\n",
            "Linha: 4 - atomo: NUMERO lexema: 10\n",
            "Linha: 4 - atomo: PONTO_VIRG lexema: ;\n",
            "Linha: 5 - atomo: PALAVRA_RESERVADA lexema: write\n",
            "Linha: 5 - atomo: ABRE_PAR lexema: (\n",
            "Linha: 5 - atomo: IDENTIFICADOR lexema: num\n",
            "Linha: 5 - atomo: FECHA_PAR lexema: )\n",
            "Linha: 5 - atomo: PONTO_VIRG lexema: ;\n",
            "Linha: 6 - atomo: PALAVRA_RESERVADA lexema: end\n",
            "Linha: 6 - atomo: PONTO lexema: .\n",
            "Erro sintático: Esperado [END] encontrado [WRITE] na linha 5\n"
          ]
        }
      ]
    }
  ]
}